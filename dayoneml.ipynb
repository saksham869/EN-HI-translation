{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12892703,"sourceType":"datasetVersion","datasetId":8157124}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install indic-nlp-library","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:37:29.824173Z","iopub.execute_input":"2025-08-28T18:37:29.824476Z","iopub.status.idle":"2025-08-28T18:37:33.703557Z","shell.execute_reply.started":"2025-08-28T18:37:29.824456Z","shell.execute_reply":"2025-08-28T18:37:33.702389Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: indic-nlp-library in /usr/local/lib/python3.11/dist-packages (0.92)\nRequirement already satisfied: sphinx-argparse in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (0.5.2)\nRequirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (0.2.4)\nRequirement already satisfied: morfessor in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (2.0.6)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2025.2)\nRequirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library) (8.2.3)\nRequirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library) (0.21.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.17.0)\nRequirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\nRequirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\nRequirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.6)\nRequirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.19.2)\nRequirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.1)\nRequirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.17.0)\nRequirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.0)\nRequirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\nRequirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.32.4)\nRequirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.0)\nRequirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (25.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->indic-nlp-library) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->indic-nlp-library) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->indic-nlp-library) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->indic-nlp-library) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->indic-nlp-library) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2025.6.15)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom transformers import AutoTokenizer\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:37:33.705552Z","iopub.execute_input":"2025-08-28T18:37:33.705858Z","iopub.status.idle":"2025-08-28T18:37:33.710952Z","shell.execute_reply.started":"2025-08-28T18:37:33.705829Z","shell.execute_reply":"2025-08-28T18:37:33.709992Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from indicnlp.tokenize import indic_tokenize","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:37:33.712062Z","iopub.execute_input":"2025-08-28T18:37:33.712325Z","iopub.status.idle":"2025-08-28T18:37:33.729248Z","shell.execute_reply.started":"2025-08-28T18:37:33.712306Z","shell.execute_reply":"2025-08-28T18:37:33.728216Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"data = pd.read_csv(\n    \"/kaggle/input/language-translation1/Sentence pairs in English-Hindi - 2025-02-11.tsv\",\n    sep=\"\\t\",\n    header=None,\n    names=[\"SrcSennId\",\"SrcSent\",\"DatSentID\",\"DatSent\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:37:33.730159Z","iopub.execute_input":"2025-08-28T18:37:33.730406Z","iopub.status.idle":"2025-08-28T18:37:33.808015Z","shell.execute_reply.started":"2025-08-28T18:37:33.730387Z","shell.execute_reply":"2025-08-28T18:37:33.807064Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:37:33.810513Z","iopub.execute_input":"2025-08-28T18:37:33.810884Z","iopub.status.idle":"2025-08-28T18:37:33.821024Z","shell.execute_reply.started":"2025-08-28T18:37:33.810860Z","shell.execute_reply":"2025-08-28T18:37:33.820312Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"   SrcSennId                                  SrcSent  DatSentID  \\\n0       1282                       Muiriel is 20 now.     485968   \n1       1282                       Muiriel is 20 now.    2060319   \n2       1294  Education in this world disappoints me.     485564   \n3       1302                       That won't happen.    2060320   \n4       1308                              I miss you.    2060321   \n\n                                       DatSent  \n0             म्यूरियल अब बीस साल की हो गई है।  \n1                   म्यूरियल अब बीस साल की है।  \n2  मैं इस दुनिया में शिक्षा पर बहुत निराश हूँ।  \n3                              वैसा नहीं होगा।  \n4                 मुझें तुम्हारी याद आ रही है।  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SrcSennId</th>\n      <th>SrcSent</th>\n      <th>DatSentID</th>\n      <th>DatSent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1282</td>\n      <td>Muiriel is 20 now.</td>\n      <td>485968</td>\n      <td>म्यूरियल अब बीस साल की हो गई है।</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1282</td>\n      <td>Muiriel is 20 now.</td>\n      <td>2060319</td>\n      <td>म्यूरियल अब बीस साल की है।</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1294</td>\n      <td>Education in this world disappoints me.</td>\n      <td>485564</td>\n      <td>मैं इस दुनिया में शिक्षा पर बहुत निराश हूँ।</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1302</td>\n      <td>That won't happen.</td>\n      <td>2060320</td>\n      <td>वैसा नहीं होगा।</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1308</td>\n      <td>I miss you.</td>\n      <td>2060321</td>\n      <td>मुझें तुम्हारी याद आ रही है।</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"# data.drop(labels=[data.columns[0], data.columns[2]], axis=1, inplace=True)\n# Save column names first\ncols_to_drop = [data.columns[0], data.columns[2]]\n\n# Drop\ndata.drop(columns=cols_to_drop, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:37:33.821858Z","iopub.execute_input":"2025-08-28T18:37:33.822094Z","iopub.status.idle":"2025-08-28T18:37:33.838983Z","shell.execute_reply.started":"2025-08-28T18:37:33.822076Z","shell.execute_reply":"2025-08-28T18:37:33.838168Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nsrc_sent_tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:37:33.839757Z","iopub.execute_input":"2025-08-28T18:37:33.840021Z","iopub.status.idle":"2025-08-28T18:37:34.670898Z","shell.execute_reply.started":"2025-08-28T18:37:33.839992Z","shell.execute_reply":"2025-08-28T18:37:34.669970Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"data[\"SrcSent\"] = data[\"SrcSent\"].apply(lambda x: src_sent_tokenizer.tokenize(x))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:37:34.672171Z","iopub.execute_input":"2025-08-28T18:37:34.672461Z","iopub.status.idle":"2025-08-28T18:37:35.587063Z","shell.execute_reply.started":"2025-08-28T18:37:34.672432Z","shell.execute_reply":"2025-08-28T18:37:35.586108Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:37:35.588031Z","iopub.execute_input":"2025-08-28T18:37:35.588376Z","iopub.status.idle":"2025-08-28T18:37:35.598420Z","shell.execute_reply.started":"2025-08-28T18:37:35.588347Z","shell.execute_reply":"2025-08-28T18:37:35.597465Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                                             SrcSent  \\\n0                  [▁Mu, i, riel, ▁is, ▁20, ▁now, .]   \n1                  [▁Mu, i, riel, ▁is, ▁20, ▁now, .]   \n2  [▁Education, ▁in, ▁this, ▁world, ▁disappoint, ...   \n3                    [▁That, ▁won, ', t, ▁happen, .]   \n4                               [▁I, ▁miss, ▁you, .]   \n\n                                       DatSent  \n0             म्यूरियल अब बीस साल की हो गई है।  \n1                   म्यूरियल अब बीस साल की है।  \n2  मैं इस दुनिया में शिक्षा पर बहुत निराश हूँ।  \n3                              वैसा नहीं होगा।  \n4                 मुझें तुम्हारी याद आ रही है।  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SrcSent</th>\n      <th>DatSent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[▁Mu, i, riel, ▁is, ▁20, ▁now, .]</td>\n      <td>म्यूरियल अब बीस साल की हो गई है।</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[▁Mu, i, riel, ▁is, ▁20, ▁now, .]</td>\n      <td>म्यूरियल अब बीस साल की है।</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[▁Education, ▁in, ▁this, ▁world, ▁disappoint, ...</td>\n      <td>मैं इस दुनिया में शिक्षा पर बहुत निराश हूँ।</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[▁That, ▁won, ', t, ▁happen, .]</td>\n      <td>वैसा नहीं होगा।</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[▁I, ▁miss, ▁you, .]</td>\n      <td>मुझें तुम्हारी याद आ रही है।</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# # data[\"DstSent\"]= data[\"DstSent\"].apply(lambda x: indic_tokenize.trivial_tokenize(x,lang=\"hi\")\n# data[\"DstSent\"] = data[\"DstSent\"].apply(\n#     lambda x: indic_tokenize.trivial_tokenize(x, lang=\"hi\")\n# )\nfrom indicnlp.tokenize import indic_tokenize\n\ndata[\"DatSent\"] = data[\"DatSent\"].apply(\n    lambda x: indic_tokenize.trivial_tokenize(x, lang=\"hi\")\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:37:35.599488Z","iopub.execute_input":"2025-08-28T18:37:35.599801Z","iopub.status.idle":"2025-08-28T18:37:35.786402Z","shell.execute_reply.started":"2025-08-28T18:37:35.599782Z","shell.execute_reply":"2025-08-28T18:37:35.785181Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"print(data.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:37:35.787222Z","iopub.execute_input":"2025-08-28T18:37:35.787481Z","iopub.status.idle":"2025-08-28T18:37:35.792569Z","shell.execute_reply.started":"2025-08-28T18:37:35.787459Z","shell.execute_reply":"2025-08-28T18:37:35.791586Z"}},"outputs":[{"name":"stdout","text":"Index(['SrcSent', 'DatSent'], dtype='object')\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# data[\"SrcSent\"]= data[\"srcSent\"].apply(arc_sent_tokenizer.convert_tokens_to_ids)\ndata[\"SrcSent_ids\"] = data[\"SrcSent\"].apply(\n    lambda tokens: src_sent_tokenizer.convert_tokens_to_ids(tokens)\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:37:35.793829Z","iopub.execute_input":"2025-08-28T18:37:35.794070Z","iopub.status.idle":"2025-08-28T18:37:35.890762Z","shell.execute_reply.started":"2025-08-28T18:37:35.794050Z","shell.execute_reply":"2025-08-28T18:37:35.890042Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"Vs = src_sent_tokenizer.get_vocab()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:37:35.891629Z","iopub.execute_input":"2025-08-28T18:37:35.891863Z","iopub.status.idle":"2025-08-28T18:37:35.927230Z","shell.execute_reply.started":"2025-08-28T18:37:35.891844Z","shell.execute_reply":"2025-08-28T18:37:35.926221Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# Vd = set()\n# for tokenized_hindi_sent in data[\"DatSent\"]:\n#     hindi_vocab.update(tokenized_hindi_sent)\n\nVd = set()\nfor sent in data[\"DatSent\"]:\n    # Convert to string (avoid NaN, lists, etc.)\n    sent = str(sent)\n    tokens = tokenizer.tokenize(sent)\n    Vd.update(tokens)\n\nprint(\"Unique tokens in dataset:\", len(Vd))\nprint(list(Vd)[:20])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:41:15.837510Z","iopub.execute_input":"2025-08-28T18:41:15.837819Z","iopub.status.idle":"2025-08-28T18:41:17.385560Z","shell.execute_reply.started":"2025-08-28T18:41:15.837798Z","shell.execute_reply":"2025-08-28T18:41:17.384587Z"}},"outputs":[{"name":"stdout","text":"Unique tokens in dataset: 557\n['रण', 'दखल', 'टन', 'लगभग', 'रप', 'थन', '२२', 'रभ', 'नम', 'भर', 'नयन', '१९', 'ञ', 'यर', 'चढ', 'यश', 'i', 'तम', 'इत', 'ऊ']\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"hindi_vocab = set()\n\nfor tokenized_hindi_sent in data[\"DatSent\"]:\n    hindi_vocab.update(tokenized_hindi_sent)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:41:27.062606Z","iopub.execute_input":"2025-08-28T18:41:27.062907Z","iopub.status.idle":"2025-08-28T18:41:27.095596Z","shell.execute_reply.started":"2025-08-28T18:41:27.062884Z","shell.execute_reply":"2025-08-28T18:41:27.094366Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"Vd = dict()\n\n# Special tokens\nVd[\"<PAD>\"] = 0\nVd[\"<SOS>\"] = 1\nVd[\"<EOS>\"] = 2\n\n# Add rest of vocab\nfor idx, token in enumerate(hindi_vocab, start=3):\n    Vd[token] = idx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:41:28.726960Z","iopub.execute_input":"2025-08-28T18:41:28.727296Z","iopub.status.idle":"2025-08-28T18:41:28.735417Z","shell.execute_reply.started":"2025-08-28T18:41:28.727271Z","shell.execute_reply":"2025-08-28T18:41:28.734599Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"def convert_hindi_token_to_ids(hindi_sent):\n    return[Vd[token] for token in hindi_sent]\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:41:32.341902Z","iopub.execute_input":"2025-08-28T18:41:32.342213Z","iopub.status.idle":"2025-08-28T18:41:32.346904Z","shell.execute_reply.started":"2025-08-28T18:41:32.342189Z","shell.execute_reply":"2025-08-28T18:41:32.345999Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"data[\"DatSent\"] = data[\"DatSent\"].apply(\n    lambda x: convert_hindi_token_to_ids(x)\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:41:33.534643Z","iopub.execute_input":"2025-08-28T18:41:33.534967Z","iopub.status.idle":"2025-08-28T18:41:33.568085Z","shell.execute_reply.started":"2025-08-28T18:41:33.534940Z","shell.execute_reply":"2025-08-28T18:41:33.567219Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"def insert_sos_token_id(hindi_sent_token_ids):\n    return [1] + hindi_sent_token_ids\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:41:34.396954Z","iopub.execute_input":"2025-08-28T18:41:34.397261Z","iopub.status.idle":"2025-08-28T18:41:34.401666Z","shell.execute_reply.started":"2025-08-28T18:41:34.397236Z","shell.execute_reply":"2025-08-28T18:41:34.400770Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"data[\"DatSentInput\"] = data[\"DatSent\"].apply(lambda x: insert_sos_token_id(x))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:41:37.812253Z","iopub.execute_input":"2025-08-28T18:41:37.812591Z","iopub.status.idle":"2025-08-28T18:41:37.825753Z","shell.execute_reply.started":"2025-08-28T18:41:37.812565Z","shell.execute_reply":"2025-08-28T18:41:37.824681Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:41:38.588621Z","iopub.execute_input":"2025-08-28T18:41:38.589490Z","iopub.status.idle":"2025-08-28T18:41:38.607426Z","shell.execute_reply.started":"2025-08-28T18:41:38.589457Z","shell.execute_reply":"2025-08-28T18:41:38.606113Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"                                             SrcSent  \\\n0                  [▁Mu, i, riel, ▁is, ▁20, ▁now, .]   \n1                  [▁Mu, i, riel, ▁is, ▁20, ▁now, .]   \n2  [▁Education, ▁in, ▁this, ▁world, ▁disappoint, ...   \n3                    [▁That, ▁won, ', t, ▁happen, .]   \n4                               [▁I, ▁miss, ▁you, .]   \n\n                                             DatSent  \\\n0  [81, 2013, 1229, 1141, 1223, 5561, 6506, 1837,...   \n1           [81, 2013, 1229, 1141, 1223, 1837, 3892]   \n2  [2098, 583, 3740, 581, 2222, 1873, 4710, 3956,...   \n3                           [1527, 3668, 3811, 3892]   \n4         [6158, 1058, 1210, 6767, 4096, 1837, 3892]   \n\n                             SrcSent_ids  \\\n0     [4159, 23, 14018, 19, 460, 230, 5]   \n1     [4159, 23, 14018, 19, 460, 230, 5]   \n2  [2855, 16, 48, 296, 26963, 7, 140, 5]   \n3            [466, 751, 31, 17, 1837, 5]   \n4                      [27, 3041, 25, 5]   \n\n                                        DatSentInput  \n0  [1, 81, 2013, 1229, 1141, 1223, 5561, 6506, 18...  \n1        [1, 81, 2013, 1229, 1141, 1223, 1837, 3892]  \n2  [1, 2098, 583, 3740, 581, 2222, 1873, 4710, 39...  \n3                        [1, 1527, 3668, 3811, 3892]  \n4      [1, 6158, 1058, 1210, 6767, 4096, 1837, 3892]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SrcSent</th>\n      <th>DatSent</th>\n      <th>SrcSent_ids</th>\n      <th>DatSentInput</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[▁Mu, i, riel, ▁is, ▁20, ▁now, .]</td>\n      <td>[81, 2013, 1229, 1141, 1223, 5561, 6506, 1837,...</td>\n      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n      <td>[1, 81, 2013, 1229, 1141, 1223, 5561, 6506, 18...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[▁Mu, i, riel, ▁is, ▁20, ▁now, .]</td>\n      <td>[81, 2013, 1229, 1141, 1223, 1837, 3892]</td>\n      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n      <td>[1, 81, 2013, 1229, 1141, 1223, 1837, 3892]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[▁Education, ▁in, ▁this, ▁world, ▁disappoint, ...</td>\n      <td>[2098, 583, 3740, 581, 2222, 1873, 4710, 3956,...</td>\n      <td>[2855, 16, 48, 296, 26963, 7, 140, 5]</td>\n      <td>[1, 2098, 583, 3740, 581, 2222, 1873, 4710, 39...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[▁That, ▁won, ', t, ▁happen, .]</td>\n      <td>[1527, 3668, 3811, 3892]</td>\n      <td>[466, 751, 31, 17, 1837, 5]</td>\n      <td>[1, 1527, 3668, 3811, 3892]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[▁I, ▁miss, ▁you, .]</td>\n      <td>[6158, 1058, 1210, 6767, 4096, 1837, 3892]</td>\n      <td>[27, 3041, 25, 5]</td>\n      <td>[1, 6158, 1058, 1210, 6767, 4096, 1837, 3892]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"def insert_eos_token_id(hindi_sent_token_ids):\n    return hindi_sent_token_ids + [2]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:41:39.046981Z","iopub.execute_input":"2025-08-28T18:41:39.047271Z","iopub.status.idle":"2025-08-28T18:41:39.052189Z","shell.execute_reply.started":"2025-08-28T18:41:39.047252Z","shell.execute_reply":"2025-08-28T18:41:39.050952Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"data[\"DatSentLavel\"] = data[\"DatSent\"].apply(\n    lambda x: insert_eos_token_id(x)\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:41:41.897197Z","iopub.execute_input":"2025-08-28T18:41:41.897490Z","iopub.status.idle":"2025-08-28T18:41:41.911282Z","shell.execute_reply.started":"2025-08-28T18:41:41.897470Z","shell.execute_reply":"2025-08-28T18:41:41.910003Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"data.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:41:42.869747Z","iopub.execute_input":"2025-08-28T18:41:42.870033Z","iopub.status.idle":"2025-08-28T18:41:42.890429Z","shell.execute_reply.started":"2025-08-28T18:41:42.870013Z","shell.execute_reply":"2025-08-28T18:41:42.888252Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"                                             SrcSent  \\\n0                  [▁Mu, i, riel, ▁is, ▁20, ▁now, .]   \n1                  [▁Mu, i, riel, ▁is, ▁20, ▁now, .]   \n2  [▁Education, ▁in, ▁this, ▁world, ▁disappoint, ...   \n3                    [▁That, ▁won, ', t, ▁happen, .]   \n4                               [▁I, ▁miss, ▁you, .]   \n\n                                             DatSent  \\\n0  [81, 2013, 1229, 1141, 1223, 5561, 6506, 1837,...   \n1           [81, 2013, 1229, 1141, 1223, 1837, 3892]   \n2  [2098, 583, 3740, 581, 2222, 1873, 4710, 3956,...   \n3                           [1527, 3668, 3811, 3892]   \n4         [6158, 1058, 1210, 6767, 4096, 1837, 3892]   \n\n                             SrcSent_ids  \\\n0     [4159, 23, 14018, 19, 460, 230, 5]   \n1     [4159, 23, 14018, 19, 460, 230, 5]   \n2  [2855, 16, 48, 296, 26963, 7, 140, 5]   \n3            [466, 751, 31, 17, 1837, 5]   \n4                      [27, 3041, 25, 5]   \n\n                                        DatSentInput  \\\n0  [1, 81, 2013, 1229, 1141, 1223, 5561, 6506, 18...   \n1        [1, 81, 2013, 1229, 1141, 1223, 1837, 3892]   \n2  [1, 2098, 583, 3740, 581, 2222, 1873, 4710, 39...   \n3                        [1, 1527, 3668, 3811, 3892]   \n4      [1, 6158, 1058, 1210, 6767, 4096, 1837, 3892]   \n\n                                        DatSentLavel  \n0  [81, 2013, 1229, 1141, 1223, 5561, 6506, 1837,...  \n1        [81, 2013, 1229, 1141, 1223, 1837, 3892, 2]  \n2  [2098, 583, 3740, 581, 2222, 1873, 4710, 3956,...  \n3                        [1527, 3668, 3811, 3892, 2]  \n4      [6158, 1058, 1210, 6767, 4096, 1837, 3892, 2]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SrcSent</th>\n      <th>DatSent</th>\n      <th>SrcSent_ids</th>\n      <th>DatSentInput</th>\n      <th>DatSentLavel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[▁Mu, i, riel, ▁is, ▁20, ▁now, .]</td>\n      <td>[81, 2013, 1229, 1141, 1223, 5561, 6506, 1837,...</td>\n      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n      <td>[1, 81, 2013, 1229, 1141, 1223, 5561, 6506, 18...</td>\n      <td>[81, 2013, 1229, 1141, 1223, 5561, 6506, 1837,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[▁Mu, i, riel, ▁is, ▁20, ▁now, .]</td>\n      <td>[81, 2013, 1229, 1141, 1223, 1837, 3892]</td>\n      <td>[4159, 23, 14018, 19, 460, 230, 5]</td>\n      <td>[1, 81, 2013, 1229, 1141, 1223, 1837, 3892]</td>\n      <td>[81, 2013, 1229, 1141, 1223, 1837, 3892, 2]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[▁Education, ▁in, ▁this, ▁world, ▁disappoint, ...</td>\n      <td>[2098, 583, 3740, 581, 2222, 1873, 4710, 3956,...</td>\n      <td>[2855, 16, 48, 296, 26963, 7, 140, 5]</td>\n      <td>[1, 2098, 583, 3740, 581, 2222, 1873, 4710, 39...</td>\n      <td>[2098, 583, 3740, 581, 2222, 1873, 4710, 3956,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[▁That, ▁won, ', t, ▁happen, .]</td>\n      <td>[1527, 3668, 3811, 3892]</td>\n      <td>[466, 751, 31, 17, 1837, 5]</td>\n      <td>[1, 1527, 3668, 3811, 3892]</td>\n      <td>[1527, 3668, 3811, 3892, 2]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[▁I, ▁miss, ▁you, .]</td>\n      <td>[6158, 1058, 1210, 6767, 4096, 1837, 3892]</td>\n      <td>[27, 3041, 25, 5]</td>\n      <td>[1, 6158, 1058, 1210, 6767, 4096, 1837, 3892]</td>\n      <td>[6158, 1058, 1210, 6767, 4096, 1837, 3892, 2]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"data.drop(labels=[data.columns[1]], axis=1, inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:41:46.661521Z","iopub.execute_input":"2025-08-28T18:41:46.661839Z","iopub.status.idle":"2025-08-28T18:41:46.669240Z","shell.execute_reply.started":"2025-08-28T18:41:46.661817Z","shell.execute_reply":"2025-08-28T18:41:46.668189Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"print(data.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:41:47.095667Z","iopub.execute_input":"2025-08-28T18:41:47.095977Z","iopub.status.idle":"2025-08-28T18:41:47.100974Z","shell.execute_reply.started":"2025-08-28T18:41:47.095952Z","shell.execute_reply":"2025-08-28T18:41:47.100132Z"}},"outputs":[{"name":"stdout","text":"Index(['SrcSent', 'SrcSent_ids', 'DatSentInput', 'DatSentLavel'], dtype='object')\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"X = list(data[\"SrcSent\"])\nY_input = list(data[\"DatSentInput\"])\nY_label = list(data[\"DatSentLavel\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:41:48.352279Z","iopub.execute_input":"2025-08-28T18:41:48.352602Z","iopub.status.idle":"2025-08-28T18:41:48.361285Z","shell.execute_reply.started":"2025-08-28T18:41:48.352580Z","shell.execute_reply":"2025-08-28T18:41:48.360321Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"X_tensor = [torch.tensor(ids) for ids in data[\"SrcSent_ids\"]]\nY_input_tensor = [torch.tensor(ids) for ids in data[\"DatSentInput\"]]  # if these are already token IDs\nY_label_tensor = [torch.tensor(ids) for ids in data[\"DatSentLavel\"]]   # if these are already token IDs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:41:49.089658Z","iopub.execute_input":"2025-08-28T18:41:49.089986Z","iopub.status.idle":"2025-08-28T18:41:49.629719Z","shell.execute_reply.started":"2025-08-28T18:41:49.089942Z","shell.execute_reply":"2025-08-28T18:41:49.628887Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"X_padded = torch.nn.utils.rnn.pad_sequence(X_tensor,batch_first=True)\nY_padded_input = torch.nn.utils.rnn.pad_sequence(Y_input_tensor,batch_first=True)\nY_padded_label = torch.nn.utils.rnn.pad_sequence(Y_label_tensor,batch_first=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:41:51.194895Z","iopub.execute_input":"2025-08-28T18:41:51.195174Z","iopub.status.idle":"2025-08-28T18:41:51.449033Z","shell.execute_reply.started":"2025-08-28T18:41:51.195155Z","shell.execute_reply":"2025-08-28T18:41:51.448307Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"\nNs = X_padded.shape[1]\nNd = Y_padded_label.shape[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:41:51.644768Z","iopub.execute_input":"2025-08-28T18:41:51.645069Z","iopub.status.idle":"2025-08-28T18:41:51.649941Z","shell.execute_reply.started":"2025-08-28T18:41:51.645039Z","shell.execute_reply":"2025-08-28T18:41:51.648900Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# class Encoder(torch.nn.module):\n#     def __init__(self.src,src_lang_vocab_size,word_embedding_dim):\n#         super(Encoder,self),__init__()\n#         self.first_embedding_layer = torch.nn.embedding(num.embedding=src_lang_VoCsL_sIZE,Embedding.dim)\n#         self.second_lstm_layer = torch.nn.LSTM() input_size = word_embedding_dim,\n#         hidden_size=word_embedding_dim,\n#         batch first= True:\n        \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:43:20.410066Z","iopub.execute_input":"2025-08-28T18:43:20.410398Z","iopub.status.idle":"2025-08-28T18:43:20.414459Z","shell.execute_reply.started":"2025-08-28T18:43:20.410376Z","shell.execute_reply":"2025-08-28T18:43:20.413613Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass Encoder(nn.Module):\n    def __init__(self, src_lang_vocab_size, word_embedding_dim, hidden_size, num_layers=1):\n        super(Encoder, self).__init__()\n        \n        # Embedding layer\n        self.embedding = nn.Embedding(num_embeddings=src_lang_vocab_size,\n                                      embedding_dim=word_embedding_dim)\n        \n        # LSTM layer\n        self.lstm = nn.LSTM(input_size=word_embedding_dim,\n                            hidden_size=hidden_size,\n                            num_layers=num_layers,\n                            batch_first=True)\n    \n    def forward(self, src):\n        # src shape: (batch_size, seq_len)\n        embedded = self.embedding(src)   # (batch_size, seq_len, word_embedding_dim)\n        outputs, (hidden, cell) = self.lstm(embedded)\n        return outputs, (hidden, cell)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T18:43:39.474850Z","iopub.execute_input":"2025-08-28T18:43:39.475151Z","iopub.status.idle":"2025-08-28T18:43:39.480973Z","shell.execute_reply.started":"2025-08-28T18:43:39.475128Z","shell.execute_reply":"2025-08-28T18:43:39.480191Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}